{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afb5a49-4180-42f7-91d5-7d1770d6af59",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d4c6ad-959c-434d-90e8-1d81f921a9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import gc\n",
    "\n",
    "from os import path\n",
    "import sys\n",
    "sys.path.append(path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e84857e-6ded-42e7-b782-e4a2b6f8110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import itertools\n",
    "import operator\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.dataset import BarCodeDataset\n",
    "from src.lightning_module import OCRModule\n",
    "from src.augmentations import get_transforms\n",
    "from src.predict_utils import matrix_to_string\n",
    "\n",
    "from onnxruntime import InferenceSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81d1715-5859-48f5-a4c6-29a723cd10ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cpu:0'\n",
    "VOCAB = '0123456789'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa70a76-7e4c-4c3d-81d5-70bb20818edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = get_transforms(\n",
    "    width=416, height=96, text_size=13, vocab=VOCAB, postprocessing=True, augmentations=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a776b878-097d-4c2c-bb68-928cee93270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/df_valid.csv')\n",
    "dataset = BarCodeDataset(df=df, data_folder='../data')\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f213f82034e89a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InferenceSession('../experiments/exp1/ocr.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf57cbc3f35498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dcfde502ad8518",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax(model.run(None, {'input': [transformed_image]})[0].transpose(1, 0, 2)).argmax(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac947dea-08b4-4e53-85b5-de0d14352613",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_texts = []\n",
    "pr_texts = []\n",
    "\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    image, text, _ = dataset[i]\n",
    "\n",
    "    transformed_image = transforms(image=image, text='')['image']\n",
    "    predict = model.run(None, {'input': [transformed_image]})[0]\n",
    "    predict = torch.as_tensor(predict)\n",
    "    string_pred, _ = matrix_to_string(predict, VOCAB)\n",
    "\n",
    "    gt_texts.append(text)\n",
    "    pr_texts.append(string_pred[0])\n",
    "\n",
    "gt_texts = np.array(gt_texts)\n",
    "pr_texts = np.array(pr_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d081fd23cb3470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(image: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    probas = softmax(x=image.transpose(1, 0, 2))\n",
    "    return probas.argmax(axis=2), probas.max(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e404ca72e972ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.run(None, {'input': [transformed_image]})[0]\n",
    "predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eac7ae32ac375c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, confidences = postprocess(predict)\n",
    "labels.shape, confidences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b13101075cd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0].shape, confidences[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5222dd004c1d2904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937e303b8e7eeb3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402b6d6c227614c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode(labels, confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e50c55368f15644",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(itertools.groupby(zip(label, confidence), operator.itemgetter(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674cfc64-093f-48f7-97d6-f1ccdd3203ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'accuracy = {np.mean(gt_texts == pr_texts)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ba37f33a3b1bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1440793c-b416-47bf-953d-d86d57102823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ошибочные индексы\n",
    "np.where(gt_texts != pr_texts)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83085d8b-5fb3-4d97-9414-19339ebe8e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 45\n",
    "image, text, _ = dataset[idx]\n",
    "print(f'pred = {pr_texts[idx]}')\n",
    "print(f'true = {gt_texts[idx]}')\n",
    "Image.fromarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65370aad-b89f-45c1-919b-2eca3b0de661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
